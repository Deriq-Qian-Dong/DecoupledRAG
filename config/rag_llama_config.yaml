trainer: RAGLanguageModelTrainer
training:
  model_type: llama
  project_name: RAG_llama3-chat
  # model_name_or_path: ../SFT-llama3
  # tokenizer_name_or_path: ../Llama-2-7b-chat-hf/
  model_name_or_path: ../llama3_chat_qa_sft
  tokenizer_name_or_path: ../llama3_chat_qa_sft
  # kg_model_name_or_path: ../llama3-chat-top8
  kg_model_name_or_path: ./output/RAG-new
  num_layers_unfrozen: -1
  gradient_checkpointing: true
  optimizer: 
    name: Lamb
    kwargs:
      lr: 1e-3
      weight_decay: 0.0
      betas: [0.9, 0.999]
      eps: 1e-08
  scheduler:
    name: LinearLR
    kwargs:
      total_iters: 10
  num_epochs: 100000
  log_with: tensorboard
  project_dir: output/
  negatives_in_device: true
  negatives_x_device: true
  predict_from_last: 10000
  eval_step: 100
  start_from: 0
  skip_steps: 0
  cross_attention_activation_function: silu
  add_cross_attention_layer_number: 31
  kb_path: ../data_of_ReGPT/En-Wiki/phrases_embeddings.npy
  freeze_retrieval_head: true
  freeze_lm_head: true

dataset:
  number_of_docs: 1
  inference_with_explict_docs_for_test: false
  train:
    hotpotqa:
      data_name_or_path: ../data_of_ReGPT/QA_datasets_WikiEmb/hotpotqa/sorted_datasets_train/
      dataset_name: QADataset4Chat
      batch_size: 16
      num_epochs: 805
      max_seq_len: 512
      dynamic_sampler: false
      corpus: ../data_of_ReGPT/Wiki-corpus/train
      max_tokens: 4096
    2WikiMultihopQA:
      data_name_or_path: ../data_of_ReGPT/QA_datasets_WikiEmb/2WikiMultihopQA/sorted_datasets_train/
      dataset_name: QADataset4Chat
      batch_size: 16
      num_epochs: 805
      max_seq_len: 512
      dynamic_sampler: false
      corpus: ../data_of_ReGPT/Wiki-corpus/train
      max_tokens: 4096
    # nq:
    #   data_name_or_path: ../data_of_ReGPT/QA_datasets_WikiEmb/nq/sorted_datasets_train
    #   dataset_name: QADataset4Chat
    #   batch_size: 16
    #   num_epochs: 805
    #   max_seq_len: 512
    #   dynamic_sampler: false
    #   corpus: ../data_of_ReGPT/Wiki-corpus/train
    #   max_tokens: 4096
    # corpus_dataset:
    #   data_name_or_path: ../data/data_of_ReGPT/Wiki-corpus/sorted_datasets_train/data-{:05d}-of-00805.arrow
    #   dataset_name: RAGPretrainFromAFSDataset
    #   batch_size: 24
    #   num_epochs: 805
    #   max_seq_len: 512
    #   dynamic_sampler: true
    #   corpus: ../data_of_ReGPT/Wiki-corpus/train
    #   max_tokens: 4096
    #   start_from: 23
  test:
    # nq:
    #   dataset_name: QADataset4ChatTest
    #   batch_size: 32
    #   data_name_or_path:  ../data_of_ReGPT/QA_datasets_WikiEmb/nq/sorted_datasets_test
    #   max_seq_len: 512
    #   max_new_tokens: 32
    #   index_path: ../data_of_ReGPT/Wiki-corpus/bm25_index/
    #   corpus: ../data_of_ReGPT/Wiki-corpus/train/
    #   dynamic_sampler: false
    hotpotqa:
      dataset_name: QADataset4ChatTest
      batch_size: 32
      data_name_or_path:  ../data_of_ReGPT/QA_datasets_WikiEmb/hotpotqa/sorted_datasets_validation/
      max_seq_len: 512
      max_new_tokens: 32
      index_path: ../data_of_ReGPT/Wiki-corpus/bm25_index/
      corpus: ../data_of_ReGPT/Wiki-corpus/train/
      dynamic_sampler: false
    2WikiMultihopQA:
      dataset_name: QADataset4ChatTest
      batch_size: 32
      data_name_or_path:  ../data_of_ReGPT/QA_datasets_WikiEmb/2WikiMultihopQA/sorted_datasets_dev/
      max_seq_len: 512
      max_new_tokens: 32
      index_path: ../data_of_ReGPT/Wiki-corpus/bm25_index/
      corpus: ../data_of_ReGPT/Wiki-corpus/train/
      dynamic_sampler: false

generation_kwargs:
  min_length: 0
  max_length: 512
  do_sample: true
  top_k: 5
  top_p: 0.95

RAG_kwargs:
  faiss:
    dimension: 768
  retrieval_step: 10
  topk: 6
